{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlopetegui98/Literary-Fine-Tuning-of-LLM/blob/main/ClassifierWildeVsMistral/clf_wild_vs_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier Wilde vs Mistral7B (baseline model)\n",
        "\n",
        "The idea is to train a classifier with texts from Oscar Wilde and texts generated by Mistral7B. Once the model is trained, it should be able to discriminate correctly between texts from both sources. The hypothesis of our work is that after fine tuning the model, we could be able to cheat the classifier."
      ],
      "metadata": {
        "id": "9q3-eFdvMiWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHvXnzagMbRE",
        "outputId": "30066d4b-70f3-478a-c7f0-5b04bd43e197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier wilde vs mistral\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U simpletransformers"
      ],
      "metadata": {
        "id": "KD3uMw_cOzhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "YASbvaboO8ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data paths\n",
        "dir_data = f'./drive/MyDrive/DL-ENS/dataset'\n",
        "authors_paths = [f'{dir_data}/wilde_complete.txt']\n",
        "mistral_gen_texts = f'{dir_data}/dataset_mistral7B_gen_texts.json'\n",
        "authors_names = [\"Wilde\", \"Mistral7B\"]"
      ],
      "metadata": {
        "id": "EQBkPD6pO9Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read the texts of an specific author\n",
        "def read_texts(path: str, label, len_to_read =None, max_length = 350):\n",
        "    text = ''\n",
        "    with open(path, 'r+') as fd:\n",
        "      text = fd.read()\n",
        "      if len_to_read != None:\n",
        "        text = text[:len_to_read]\n",
        "    text_splited = text.split()\n",
        "    dt = {'text': [], 'label': []}\n",
        "    for i in range(0,len(text_splited),max_length):\n",
        "      text = ' '.join(text_splited[i:min(i+max_length, len(text_splited))])\n",
        "      dt['text'].append(text)\n",
        "      dt['label'].append(label)\n",
        "    return dt"
      ],
      "metadata": {
        "id": "8qyZsrnPPVuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get wilde texts\n",
        "dt = {'text': [], 'label': []}\n",
        "for i,path in enumerate(authors_paths):\n",
        "  dt_i = read_texts(path,i,len_wilde_texts)\n",
        "  dt['text'].extend(dt_i['text'])\n",
        "  dt['label'].extend(dt_i['label'])"
      ],
      "metadata": {
        "id": "bEDEzZrPPcQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get mistral generated texts\n",
        "with open(mistral_gen_texts, 'r+') as fd:\n",
        "  mistral_texts = json.load(fd)\n",
        "\n",
        "dt['text'].extend(mistral_texts['texts'])\n",
        "dt['label'].extend(1)"
      ],
      "metadata": {
        "id": "QIHPctRkQAKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the dataset to DataFrame\n",
        "dt = DataFrame.from_dict(dt)\n",
        "dt.head()"
      ],
      "metadata": {
        "id": "STJejuclQxh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_train, dt_test = train_test_split(dt, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "Q2ALlnzAQ1dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_train.head()"
      ],
      "metadata": {
        "id": "l5UDiWhDQ5em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_test.head()"
      ],
      "metadata": {
        "id": "Zir21hJQQ-1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_train.hist()"
      ],
      "metadata": {
        "id": "PyfXb9teRBk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_test.hist()"
      ],
      "metadata": {
        "id": "WNig6GbXREDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model for classifier and initial weights\n",
        "model_name = 'bert'\n",
        "model_weights =  'bert-base-cased'"
      ],
      "metadata": {
        "id": "mS-Ktu4BRE82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ClassificationModel(model_name, model_weights, num_labels=2, weight = [1 - sum(dt_train['label'])/len(dt_train['label']), sum(dt_train['label'])/len(dt_train['label'])], args={'reprocess_input_data': True, 'overwrite_output_dir': True,  'num_train_epochs' : 5}, use_cuda=True)\n",
        "model.train_model(dt_train)"
      ],
      "metadata": {
        "id": "PN6dVQ5fRHu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, raw_out = model.predict(list(dt_test['text']))"
      ],
      "metadata": {
        "id": "9JvKn13IRQFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(dt_test['label'], predictions, target_names = authors_names))"
      ],
      "metadata": {
        "id": "tPFvDY55RVlo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}